
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Introduction &#8212; swyft 0.1 documentation</title>
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h1>
<p>Parametric stochastic simulators are ubiquitous in the physical sciences
 [1–3]. However, performing parameter inference based on simulator runs
using Markov chain Monte Carlo is inconvenient or even impossible if the
model parameter space is large or the likelihood function is
intractable. This problem is addressed by so-called likelihood-free
inference  [4] or simulation-based inference  [5] techniques. Deep
learning based likelihood-free inference algorithms were organized into
a taxonomy in Ref.  [6], where methods that estimated likelihood ratios
in a series of rounds were denoted Sequential Ratio Estimation
(SRE)  [7]. Our presented method is closely related.</p>
<p>We propose <em>Nested Ratio Estimation</em> (NRE), which approximates the
likelihood-to-evidence ratio in a sequence of rounds. Loosely inspired
by the contour sorting method of nested sampling  [8–10], the scheme
alternates between sampling from a constrained prior and estimating
likelihood-to-evidence ratios. It allows for efficient estimation of any
marginal posteriors of interest. Furthermore, we propose an algorithm
that we call <em>iP3 sample caching</em>, which facilitates simulator
efficiency by automatizing the reuse of previous simulator runs through
resampling of cached simulations.</p>
<p>The primary use case for these algorithms is the calculation of
arbitrary, low-dimensional marginal posteriors, typically in one or two
dimensions. In physics and astronomy, such marginals serve as the basis
for scientific conclusions by constraining individual model parameters
within uncertainty bounds. We implement a multi-target training regime
where all marginal posteriors of interest can be learned simultaneously.
We find that learning is simplified when one calculates each marginal
distribution directly rather than computing the full joint posterior and
marginalizing numerically. Furthermore, the method facilitates
effortless marginalization over arbitrary numbers of nuisance
parameters, increasing its utility in high-dimensional parameter
regimes–even to simulators with a tractable, yet high-dimensional,
likelihood  [11].</p>
</div>
<div class="section" id="nested-ratio-estimation-nre">
<h1>Nested Ratio Estimation (NRE).<a class="headerlink" href="#nested-ratio-estimation-nre" title="Permalink to this headline">¶</a></h1>
<p>We operate in the context of simulation-based inference where our
simulator <span class="math notranslate nohighlight">\(\mathbf{g}\)</span> is a nonlinear function mapping a vector of
parameters
<span class="math notranslate nohighlight">\(\boldsymbol{\theta}= (\theta_{1}, \dots, \theta_{d}) \in \mathbb{R}^{d}\)</span>
and a stochastic latent state <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> to an observation
<span class="math notranslate nohighlight">\(\mathbf{x}= \mathbf{g}(\boldsymbol{\theta}, \mathbf{z})\)</span>. The
likelihood function is therefore
<span class="math notranslate nohighlight">\(p(\mathbf{x}\vert \boldsymbol{\theta}) = \int \delta(\mathbf{x}- \mathbf{g}(\boldsymbol{\theta}, \mathbf{z})) \, p(\mathbf{z}\vert \boldsymbol{\theta}) \, d\mathbf{z}\)</span>,
with <span class="math notranslate nohighlight">\(\delta(\cdot)\)</span> denoting the Dirac delta. Consider a
factorizable prior
<span class="math notranslate nohighlight">\(p(\boldsymbol{\theta}) = p(\theta_{1}) \cdots p(\theta_{d})\)</span> over
the parameters, the joint posterior is given via Bayes’ rule as
<span class="math notranslate nohighlight">\(p(\boldsymbol{\theta}|\mathbf{x}) = p(\mathbf{x}|\boldsymbol{\theta})p(\boldsymbol{\theta})/p(\mathbf{x})\)</span>,
where <span class="math notranslate nohighlight">\(p(\mathbf{x})\)</span> is the evidence.</p>
<p>Our goal is to compute the marginal posterior,
<span class="math notranslate nohighlight">\(p(\boldsymbol{\vartheta}\vert \mathbf{x})\)</span>, where
<span class="math notranslate nohighlight">\(\boldsymbol{\vartheta}\)</span> are the parameters of interest. We will
denote all other parameters by <span class="math notranslate nohighlight">\(\boldsymbol{\eta}\)</span>, such that
<span class="math notranslate nohighlight">\(\boldsymbol{\theta}= (\boldsymbol{\vartheta}, \boldsymbol{\eta})\)</span>.
The marginal posterior is obtained from the joint distribution
<span class="math notranslate nohighlight">\(p(\boldsymbol{\vartheta}, \boldsymbol{\eta}|\mathbf{x}) \equiv p(\boldsymbol{\theta}|\mathbf{x})\)</span>
by integrating over all components of <span class="math notranslate nohighlight">\(\boldsymbol{\eta}\)</span>,</p>
<div class="math notranslate nohighlight">
\[\label{eqn:post}
p(\boldsymbol{\vartheta}\vert \mathbf{x})  \equiv \int p(\boldsymbol{\vartheta}, \boldsymbol{\eta}| \mathbf{x}) d\boldsymbol{\eta}
= \int \frac{p(\mathbf{x}| \boldsymbol{\vartheta}, \boldsymbol{\eta})}{p(\mathbf{x})}
p(\boldsymbol{\theta})
%\prod_{j \notin \texttt{idx}} d\theta_{j}
d\boldsymbol{\eta}
= \frac{p(\mathbf{x}|\boldsymbol{\vartheta})}{p(\mathbf{x})}p(\boldsymbol{\vartheta})\;,\]</div>
<p>where we used Bayes’ rule and defined the marginal likelihood
<span class="math notranslate nohighlight">\(p(\mathbf{x}|\boldsymbol{\vartheta})\)</span> in the last step.</p>
<p>Just like in SRE, we focus on a specific observation of interest,
<span class="math notranslate nohighlight">\(\mathbf{x}_0\)</span>. Only parameter values <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>
that could have plausibly generated observation <span class="math notranslate nohighlight">\(\mathbf{x}_0\)</span>
will significantly contribute to the integrals in
Eq. <a class="reference external" href="#eqn:post">[eqn:post]</a>. For implausible values the likelihood
<span class="math notranslate nohighlight">\(p(\mathbf{x}_0|\boldsymbol{\theta})\)</span> will be negligible. We
denote priors that are suitably constrained to plausible parameter
values by <span class="math notranslate nohighlight">\(\tilde{p}(\theta_1, \dots, \theta_d)\)</span>. Similarly,
<span class="math notranslate nohighlight">\(\tilde{\square}\)</span> indicates quantities <span class="math notranslate nohighlight">\(\square\)</span> that are
calculated using the constrained prior. Therefore, using a judiciously
chosen constrained prior, accurately approximates the marginal posterior
in place of our true prior beliefs,</p>
<div class="math notranslate nohighlight">
\[p(\boldsymbol{\vartheta}| \mathbf{x}_0) =
\frac{p(\mathbf{x}_0|\boldsymbol{\vartheta})}{p(\mathbf{x}_0)} p(\boldsymbol{\vartheta}) \simeq
\frac{\tilde{p}(\mathbf{x}_0|\boldsymbol{\vartheta})}{\tilde{p}(\mathbf{x}_0)} \tilde{p}(\boldsymbol{\vartheta})\;.\]</div>
<p>The increased probability that constrained priors assign to the
plausible parameter region cancels when dividing by the constrained
evidence <span class="math notranslate nohighlight">\(\tilde p(\mathbf{x})\)</span>. We define the marginal
likelihood-to-evidence ratio</p>
<div class="math notranslate nohighlight">
\[\label{eqn:likelihood_ratio}
    \tilde{r}(\mathbf{x}, \boldsymbol{\vartheta})
    \equiv \frac{\tilde{p}(\mathbf{x}\vert \boldsymbol{\vartheta})}{\tilde{p}(\mathbf{x})}
    = \frac{\tilde{p}(\mathbf{x}, \boldsymbol{\vartheta})}{\tilde{p}(\mathbf{x}) \tilde{p}(\boldsymbol{\vartheta})}
    = \frac{\tilde{p}(\boldsymbol{\vartheta}\vert\mathbf{x})}{\tilde{p}(\boldsymbol{\vartheta})}\;,\]</div>
<p>which is sufficient to evaluate the marginal posterior in
Eq. <a class="reference external" href="#eqn:post">[eqn:post]</a>, and which we will now estimate. Under
the assumption of equal class population, it is known  [6,12] that one
can recover density ratios using binary classification to distinguish
between samples from two distributions. Our binary classification
problem is to distinguish positive samples,
<span class="math notranslate nohighlight">\((\mathbf{x}, \boldsymbol{\vartheta}) \sim \tilde{p}(\mathbf{x}, \boldsymbol{\vartheta}) = p(\mathbf{x}\vert \boldsymbol{\vartheta}) \tilde{p}(\boldsymbol{\vartheta})\)</span>,
drawn jointly, and negative samples,
<span class="math notranslate nohighlight">\((\mathbf{x}, \boldsymbol{\vartheta}) \sim \tilde{p}(\mathbf{x}) \tilde{p}(\boldsymbol{\vartheta})\)</span>,
drawn marginally. The binary classifier
<span class="math notranslate nohighlight">\(\sigma(f_{\phi}(\mathbf{x}, \boldsymbol{\vartheta}))\)</span> performs
optimally when
<span class="math notranslate nohighlight">\(f_{\phi}(\mathbf{x}, \boldsymbol{\vartheta}) = \log \tilde{r}(\mathbf{x}, \boldsymbol{\vartheta})\)</span>,
where <span class="math notranslate nohighlight">\(\sigma(\cdot)\)</span> is the sigmoid function and <span class="math notranslate nohighlight">\(f_{\phi}\)</span>
is a neural network parameterized by <span class="math notranslate nohighlight">\(\phi\)</span>. The associated binary
cross-entropy loss function used to train the ratio
<span class="math notranslate nohighlight">\(\tilde{r}(\boldsymbol{\vartheta}, \mathbf{x}_0)\)</span> via stochastic
gradient descent is given by</p>
<div class="math notranslate nohighlight">
\[\ell = -\int \left[ \tilde{p}(\mathbf{x}|\boldsymbol{\vartheta})\tilde{p}(\boldsymbol{\vartheta}) \ln \sigma(f_\phi(\mathbf{x}, \boldsymbol{\vartheta})) + \tilde{p}(\mathbf{x})\tilde{p}(\boldsymbol{\vartheta}) \ln \sigma(-f_\phi(\mathbf{x},\boldsymbol{\vartheta})) \right] d\mathbf{x}\, d\boldsymbol{\vartheta}\;.\]</div>
<p>We propose to iteratively improve marginal posterior estimates in
<span class="math notranslate nohighlight">\(R\)</span> rounds by employing posterior estimates from previous rounds
to define constrained priors. In each round <span class="math notranslate nohighlight">\(r\)</span>, we estimate <em>all</em>
1-dim marginal posteriors, using <span class="math notranslate nohighlight">\(d\)</span> instances of the above
marginal likelihood-to-evidence ratio estimation in parallel by setting
<span class="math notranslate nohighlight">\(\boldsymbol{\vartheta}= (\theta_i)\)</span> for <span class="math notranslate nohighlight">\(i=1, \dots, d\)</span>. To
this end, we utilize the factorized constrained prior,
<span class="math notranslate nohighlight">\(\tilde{p}_r(\theta) = \tilde{p}_r(\theta_1)\cdots\tilde{p}_r(\theta_d)\)</span>,
which is defined recursively by a cutoff criterion,</p>
<div class="math notranslate nohighlight">
\[\tilde{p}_{r}(\theta_{i})
    \propto
    p(\theta_{i}) \Theta_{H} \left[ \frac{\tilde{r}_{r-1}(\theta_{i}, \mathbf{x})}{\max_{\theta_{i}} \tilde{r}_{r-1}(\theta_{i}, \mathbf{x})} - \epsilon \right],
    \label{eqn:it}\]</div>
<p>where <span class="math notranslate nohighlight">\(\Theta_{H}\)</span> denotes the Heaviside step function and
<span class="math notranslate nohighlight">\(\epsilon\)</span> denotes the minimum likelihood-ratio which passes
through the threshold. We use
<span class="math notranslate nohighlight">\(\tilde{p}_1(\boldsymbol{\theta}) = p(\boldsymbol{\theta})\)</span> as an
initial prior in the iterative scheme.</p>
<p>In every round, each 1-dim posterior approximates a marginalization of
the same underlying constrained posterior, allowing us to effectively
reuse training data and train efficiently in a multi-target regime. The
inference network is therefore divided into a featurizer
<span class="math notranslate nohighlight">\(\mathbf{F}(\mathbf{x})\)</span> with shared parameters and a set of
<span class="math notranslate nohighlight">\(d\)</span> independent Multi-layer Perceptons
<span class="math notranslate nohighlight">\(\{\textrm{MLP}_i(\cdot, \cdot)\}_{i=1}^{d}\)</span> which estimate
individual 1-dim marginal posteriors and do not share parameters, such
that
<span class="math notranslate nohighlight">\(f_{\phi}(\mathbf{x}, \theta_i) = \textrm{MLP}_i(\mathbf{F}(\mathbf{x}), \theta_i)\)</span>.</p>
<p>This technique is valid as long as the excluded prior regions do not
significantly affect the integrals in Eq. <a class="reference external" href="#eqn:post">[eqn:post]</a>.
For uncorrelated parameters, a sufficient criterion is that the impact
on the marginal posteriors is small, which we guarantee through the
iteration criterion Eq. <a class="reference external" href="#eqn:it">[eqn:it]</a>. In the case of a very
large number of strongly correlated parameters the algorithm can
inadvertently cut away tails of the marginal posteriors. Decreasing
<span class="math notranslate nohighlight">\(\epsilon\)</span> mitigates this effect. Discussion is left for future
study  [13].</p>
<p>With this design, the posteriors from the final round can be used to
approximate the true 1-dim marginal posteriors,
<span class="math notranslate nohighlight">\(\tilde{p}_{R}(\theta_i \vert \mathbf{x}_{0}) \approx p(\theta_i\vert \mathbf{x}_{0})\)</span>,
while previous rounds were used to iteratively focus on relevant parts
of the parameter space. The key result and value of NRE lies in the
utility of our constrained prior from round <span class="math notranslate nohighlight">\(R\)</span>. The final
constrainted prior, along with previously generated and cached samples,
allows for estimation of <em>any</em> higher dimensional marginal posterior
<span class="math notranslate nohighlight">\(\tilde{p}_R(\boldsymbol{\vartheta}|\mathbf{x}_0) \approx p(\boldsymbol{\vartheta}|\mathbf{x}_0)\)</span>
of interest by doing likelihood-to-evidence ratio estimation, often
without further simulation.</p>
</div>
<div class="section" id="inhomogeneous-poisson-point-process-ip3-sample-caching">
<h1>Inhomogeneous Poisson Point Process (iP3) Sample Caching.<a class="headerlink" href="#inhomogeneous-poisson-point-process-ip3-sample-caching" title="Permalink to this headline">¶</a></h1>
<p>Simulating
<span class="math notranslate nohighlight">\((\mathbf{x}, \boldsymbol{\theta})\sim p(\mathbf{x}|\boldsymbol{\theta})p(\boldsymbol{\theta})\)</span>
can be extremely expensive. We develop a scheme to systematically reuse
appropriate subsets of previous simulator runs. Our method samples
<span class="math notranslate nohighlight">\(N\sim \text{Pois}(\hat N)\)</span> parameter vectors from an arbitrary
distribution <span class="math notranslate nohighlight">\(p(\boldsymbol{\theta})\)</span>, where <span class="math notranslate nohighlight">\(\hat N\)</span> is the
expected number of samples. Taking <span class="math notranslate nohighlight">\(N\)</span> samples from
<span class="math notranslate nohighlight">\(p(\boldsymbol{\theta})\)</span> is equivalent to drawing a single sample
<span class="math notranslate nohighlight">\(\Theta \equiv \{\boldsymbol{\theta}^{(n)}\}_{n=1}^{N}\)</span> from an
inhomogenous Poisson point process (PPP) with intensity function
<span class="math notranslate nohighlight">\(\lambda_{r}(\boldsymbol{\theta}) = \hat{N} p(\boldsymbol{\theta})\)</span>.
In this context, <span class="math notranslate nohighlight">\(\Theta\)</span> is known as a set of <em>points</em>. This
formulation provides convenient mathematical properties  [14], at the
low price of introducing variance in the number of samples drawn. The
precise number of samples doesn’t matter as long as
<span class="math notranslate nohighlight">\(N \approx \hat{N}\)</span>, which is true in our regime of order
<span class="math notranslate nohighlight">\(\geq 1000\)</span>.</p>
<p>We will need two properties of PPPs. <em>Superposition:</em> Given two
independent PPPs with intensity functions
<span class="math notranslate nohighlight">\(\lambda_{1}(\boldsymbol{\theta})\)</span> and
<span class="math notranslate nohighlight">\(\lambda_{2}(\boldsymbol{\theta})\)</span>, the sum yields another PPP
with intensity function
<span class="math notranslate nohighlight">\(\lambda(\boldsymbol{\theta}) = \lambda_{1}(\boldsymbol{\theta}) + \lambda_{2}(\boldsymbol{\theta})\)</span>.
The union of two sets of points <span class="math notranslate nohighlight">\(\Theta = \Theta_1 \cup \Theta_2\)</span>
from the individual PPPs is equivalent to a single set of points from
the combined PPP. <em>Thinning:</em> Consider a PPP with intensity function
<span class="math notranslate nohighlight">\(\lambda(\boldsymbol{\theta})\)</span>, and an arbitrary function
<span class="math notranslate nohighlight">\(q(\boldsymbol{\theta}): \mathbb{R}^{d} \to [0, 1]\)</span>. If we are
interested in drawing from a PPP with intensity function
<span class="math notranslate nohighlight">\(\lambda_{q}(\boldsymbol{\theta}) = q(\boldsymbol{\theta}) \lambda(\boldsymbol{\theta})\)</span>,
we can achieve this by drawing a set of points <span class="math notranslate nohighlight">\(\Theta\)</span>
distributed like <span class="math notranslate nohighlight">\(\lambda(\boldsymbol{\theta})\)</span> and then rejecting
individual points <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(n)}\)</span> with probability
<span class="math notranslate nohighlight">\(1 - q(\boldsymbol{\theta}^{(n)})\)</span>.</p>
<p>The parameter cache is defined by a set of points <span class="math notranslate nohighlight">\(\Theta_{sc}\)</span>
drawn from a PPP with intensity function
<span class="math notranslate nohighlight">\(\lambda_{sc}(\boldsymbol{\theta})\)</span>. For every point
<span class="math notranslate nohighlight">\(\boldsymbol{\theta}\in\Theta_{sc}\)</span>, a corresponding observation
<span class="math notranslate nohighlight">\(\mathbf{x}\)</span> is stored in an observation cache
<span class="math notranslate nohighlight">\(\mathcal{X}_{sc}\)</span>. The iP3 cache sampling algorithm that is
responsible for maintaining the caches and sampling from a PPP with
target intensity function
<span class="math notranslate nohighlight">\(\lambda_t(\boldsymbol{\theta}) = \hat{N} p(\boldsymbol{\theta})\)</span>
is written out in the supplementary material. It is summarized in two
steps: First, consider all points
<span class="math notranslate nohighlight">\(\boldsymbol{\theta}\in \Theta_{sc}\)</span> from the cache and accept
them with probability
<span class="math notranslate nohighlight">\(\min(1, \lambda_t(\boldsymbol{\theta})/\lambda_{sc}(\boldsymbol{\theta}))\)</span>.
The thinning operation yields a sample <span class="math notranslate nohighlight">\(\Theta_1\)</span> from a PPP with
intensity function
<span class="math notranslate nohighlight">\(\lambda_1(\boldsymbol{\theta}) = \min(\lambda_t(\boldsymbol{\theta}), \lambda_{sc}(\boldsymbol{\theta}))\)</span>.
Second, draw a new set of points <span class="math notranslate nohighlight">\(\Theta_p\)</span> from
<span class="math notranslate nohighlight">\(\lambda_t(\boldsymbol{\theta})\)</span>, and accept each
<span class="math notranslate nohighlight">\(\boldsymbol{\theta}\in\Theta_p\)</span> with probability
<span class="math notranslate nohighlight">\(\max(0, 1-\lambda_{sc}(\boldsymbol{\theta})/\lambda_t(\boldsymbol{\theta}))\)</span>.
This yields a sample <span class="math notranslate nohighlight">\(\Theta_2\)</span> from a PPP with intensity function
<span class="math notranslate nohighlight">\(\lambda_2(\boldsymbol{\theta}) = \max(0, \lambda_t(\boldsymbol{\theta}) - \lambda_{sc}(\boldsymbol{\theta}))\)</span>.
Thanks to superposition, the union
<span class="math notranslate nohighlight">\(\Theta_1 \cup \Theta_2 = \Theta_t\)</span> yields a sample from the PPP
with intensity function <span class="math notranslate nohighlight">\(\lambda_t(\boldsymbol{\theta})\)</span>–the
sample we were looking for. We only need to run simulations on points
from <span class="math notranslate nohighlight">\(\Theta_1\)</span>. Points in <span class="math notranslate nohighlight">\(\Theta_2\)</span> already have
corresponding observations in <span class="math notranslate nohighlight">\(\mathcal{X}_{sc}\)</span> which we can
reuse. Finally, the new parameters are appended to the set of points in
the parameter cache, <span class="math notranslate nohighlight">\(\Theta_{sc} \to \Theta_{sc} \cup \Theta_2\)</span>.
Similar for <span class="math notranslate nohighlight">\(\mathcal{X}_{sc}\)</span>. On the basis of the superposition
principle, the intensity function of the <span class="math notranslate nohighlight">\(\Theta_{sc}\)</span> cache is
updated
<span class="math notranslate nohighlight">\(\lambda_{sc}(\boldsymbol{\theta}) \to \max(\lambda_{sc}(\boldsymbol{\theta}), \lambda_t(\boldsymbol{\theta}))\)</span>.</p>
<p>Storing and updating the parameter cache’s intensity function
<span class="math notranslate nohighlight">\(\lambda_{sc}(\boldsymbol{\theta})\)</span> can pose challenges when it is
complex and high-dimensional. Our NRE implementation overcomes these
challenges by learning marginal 1-dim posteriors, guaranteeing that the
relevant target intensities always factorize,
<span class="math notranslate nohighlight">\(\lambda_t(\boldsymbol{\theta}) = \lambda_t(\theta_1)\cdots \lambda_t(\theta_d)\)</span>.
Storage of and calculation with factorizable functions simplifies
matters.</p>
<div class="references csl-bib-body docutils container" id="refs">
<div class="csl-entry docutils container" id="ref-banik-2018">
<p>[1]N. Banik, G. Bertone, J. Bovy, and N. Bozorgnia, Probing the
Nature of Dark Matter Particles with Stellar Streams, Journal of
Cosmology and Astroparticle Physics 2018, 061 (2018).</p>
</div>
<div class="csl-entry docutils container" id="ref-bartels-2016">
<p>[2]R. Bartels, S. Krishnamurthy, and C. Weniger, Strong Support
for the Millisecond Pulsar Origin of the Galactic Center GeV
Excess, Physical Review Letters 116, (2016).</p>
</div>
<div class="csl-entry docutils container" id="ref-rodr-guez-puebla-2016">
<p>[3]A. Rodríguez-Puebla, P. Behroozi, J. Primack, A. Klypin, C.
Lee, and D. Hellinger, Halo and Subhalo Demographics with Planck
Cosmological Parameters: Bolshoi–Planck and MultiDark–Planck
Simulations, Monthly Notices of the Royal Astronomical Society
462, 893 (2016).</p>
</div>
<div class="csl-entry docutils container" id="ref-sisson2018handbook">
<p>[4]S. A. Sisson, Y. Fan, and M. Beaumont, Handbook of Approximate
Bayesian Computation (CRC Press, 2018).</p>
</div>
<div class="csl-entry docutils container" id="ref-cranmer2020">
<p>[5]K. Cranmer, J. Brehmer, and G. Louppe, The Frontier of
Simulation-Based Inference, Proc. Natl. Acad. Sci. U. S. A.
(2020).</p>
</div>
<div class="csl-entry docutils container" id="ref-durkan2020">
<p>[6]C. Durkan, I. Murray, and G. Papamakarios, On Contrastive
Learning for Likelihood-Free Inference, (2020).</p>
</div>
<div class="csl-entry docutils container" id="ref-hermans2019">
<p>[7]J. Hermans, V. Begy, and G. Louppe, Likelihood-Free MCMC with
Amortized Approximate Ratio Estimators, (2019).</p>
</div>
<div class="csl-entry docutils container" id="ref-skilling2006">
<p>[8]J. Skilling, Nested Sampling for General Bayesian Computation,
Bayesian Anal. 1, 833 (2006).</p>
</div>
<div class="csl-entry docutils container" id="ref-feroz2008">
<p>[9]F. Feroz, M. P. Hobson, and M. Bridges, MultiNest: An Efficient
and Robust Bayesian Inference Tool for Cosmology and Particle
Physics, Mon. Not. Roy. Astron. Soc. 398: 1601-1614,2009 (2008).</p>
</div>
<div class="csl-entry docutils container" id="ref-handley2015">
<p>[10]W. J. Handley, M. P. Hobson, and A. N. Lasenby, Polychord :
Next-Generation Nested Sampling, Mon. Not. R. Astron. Soc. 453,
4384 (2015).</p>
</div>
<div class="csl-entry docutils container" id="ref-lensing">
<p>[11]A. et. al., Precision Analysis of Gravitational Strong Lensing
Images with Nested Likelihood-Free Inference, (2020).</p>
</div>
<div class="csl-entry docutils container" id="ref-cranmer2015">
<p>[12]K. Cranmer, J. Pavez, and G. Louppe, Approximating Likelihood
Ratios with Calibrated Discriminative Classifiers, (2015).</p>
</div>
<div class="csl-entry docutils container" id="ref-swyft-future">
<p>[13]A. et. al., Nested Ratio Estimation and iP3 Sample Caching,
(2020).</p>
</div>
<div class="csl-entry docutils container" id="ref-ppp">
<p>[14]J. F. C. Kingman, Poisson Processes (Oxford University Press,
1993).</p>
</div>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">swyft</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, AC,BM,CW.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.3.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/theorytex.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>